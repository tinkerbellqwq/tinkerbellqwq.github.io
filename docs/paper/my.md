# 医学报告生成

## Automatic Radiology Reports Generation via Memory Alignment Network （AAAI 2024）

- 动机：医学影像和文本的跨模态对齐（cross-modal alignment）困难，前人工作有依靠分类器的疾病标签与文本对齐，这依赖分类器的高精度，一旦分类错误将导致后续所有任务；此外，还有人采用了记忆矩阵，作为知识库，所有的图像和文本都可以从中查询特征，从而间接的实现了对齐。本文从记忆矩阵的局限性出发：记忆矩阵存在双重任务，既要学习表征，又要学习对齐，职责不专一，并且效率十分低下，因为它在生成报告时，每生成一个新词都需要重新查询一次记忆矩阵。

- 创新点：

    - 机制创新：提出了一个解耦的记忆对齐（Decoupled Memory Alignment）模块。它将特征表示（Representation）和对齐（Alignment）这两个任务分开，让记忆矩阵只专注于对 - 齐，从而学习更纯粹的跨模态映射关系。
    - 效率创新：对齐过程被设计为一次性计算（One-time Calculation）。在送入BERT生成器之前，所有视觉特征的对齐嵌入可以一次性全部计算完成，与CMN逐词计算的方式形成鲜明对比，极大地提升了推理速度。
    - 信息融合创新：在构建查询（Query）时，巧妙地融合了视觉特征和其对应的位置嵌入（Positional Embedding）。这为对齐模块引入了空间位置的“常识”，使其能更好地理解图像布局，做出更鲁棒的对齐。

- 核心方法：将视觉特征，利用记忆矩阵进行类似注意力操作获取对齐特征，在送入BERT之前，我们可以一次性把所有视觉特征进行对齐，从而实现了高效率。

- 实验结果：


| 数据集 | B@1 | B@2 | B@3 | B@4 | M | R |
| --- | --- | --- | --- | --- | --- | --- |
| MIMIC-CXR | 0.396 | 0.244 | 0.162 | 0.115 | 0.151 | 0.274 |
| IU X-Ray | 0.501 | 0.328 | 0.230 | 0.170 | 0.213 | 0.386 |


---

## DART: Disease-aware Image-Text Alignment and Self-correcting Re-alignment for Trustworthy Radiology Report Generation (CVPR 2025)

- 动机： 现有的放射学报告生成方法存在两大核心痛点。首先，许多依赖检索相似报告的方法，难以保证检索到的报告在疾病层面与输入的X光片真正匹配，因为视觉上的相似不等于病理学上的相似 。其次，绝大多数模型采用“一站式”生成模式，缺乏对已生成报告进行反思和修正的机制，导致报告可能存在事实错误或遗漏。

- 创新点：
    - 疾病感知的对齐机制： 论文创新性地引入了“疾病感知的”对齐方式 。它通过一个疾病分类器提取与疾病直接相关的特征 ，并设计了一个疾病匹配约束（disease-matching constraint, γ） ，强制要求检索到的参考报告必须与输入图像的疾病标签相符，极大地提升了参考信息的可靠性 。
    - 自校正重对齐（Self-Correction）： 本文首次将自校正机制引入放射学报告生成领域 。它设计了一个独立的第二阶段，专门用于修正第一阶段生成的初步报告 。其核心是通过最小化一个修正损失（correction loss, L cor），在嵌入空间中将已生成报告的特征“拉回”到原始图像特征的位置，从而实现内容的精炼和修正 。
    - 两阶段解耦架构： 整个框架被清晰地解构成“初步生成”和“修正重对齐”两个阶段 ，使得每个阶段的任务更纯粹，优化更稳定。

- 核心方法：采用两阶段流程。阶段一，通过对比学习构建图文共享空间 ，并利用疾病分类器和疾病匹配约束来检索高质量的参考报告 ，最终生成一份初步报告。阶段二，将初步报告的特征通过一个自校正模块进行处理，该模块以最小化与原始图像特征的距离为目标 ，产出修正后的特征，并生成最终的、更精确的报告。

- 实验结果：


| 数据集 | B@1 | B@2 | B@3 | B@4 | M | R |
| --- | --- | --- | --- | --- | --- | --- |
| MIMIC-CXR | 0.437 | 0.279 | 0.191 | 0.137 | 0.175 | 0.310 |
| IU X-Ray | 0.486 | 0.348 | 0.265 | 0.208 | 0.205 | 0.411 |

--- 

## Enhanced Contrastive Learning with Multi-view Longitudinal Data for Chest X-ray Report Generation (CVPR 2025)

- 动机： 现有的报告生成模型与临床放射科医生的实际诊断流程存在脱节。医生通常会综合分析多视图（如正位、侧位）影像和纵向（历史）数据来追踪病情变化 。而现有方法大多只处理单视图影像，忽略了空间信息的完整性 ；即便有些方法引入了纵向数据，也仍然只用单张图像分析当前病情，限制了准确性 ；此外，现有模型普遍缺乏对患者数据不完整（如缺少历史报告）情况的鲁棒处理能力。

- 创新点： 
    - 多视图纵向数据融合： 论文的核心创新在于其框架能够灵活地整合来自当前就诊的多视图空间信息和来自历史就诊的纵向时间信息 。为此，它设计了一个专门的多视图纵向融合网络（MLF Network）
    - 多正例对比学习（Multi-positive Contrastive Learning）： 提出了一种新颖的对比学习策略，它将同一次就诊中的所有不同视图图像都视为“正样本对” 。这种方法能有效学习到对于不同拍摄视角的不变性特征，提升了视觉表征的一致性。
    - 标记化缺失编码（Tokenized Absence Encoding）： 为了解决真实世界中数据缺失的问题，论文首创了一种编码技术。它使用[NHI]等特殊字符来显式地表示“INDICATION”等先验知识的缺失，使模型能灵活、鲁棒地处理各种数据不完整的场景。

- 核心方法： 采用两阶段流程。阶段一（预训练），通过多正例对比损失（L_MPC）和跨模态对齐损失（L_G）学习高质量的图文表征。其中，MLF网络负责将多视图和纵向影像融合成统一的时空特征 。阶段二（生成），利用预训练好的模型，通过标记化缺失编码技术处理可能缺失的患者先验知识 ，再将所有信息融合后送入文本生成器（DistilGPT2）产出最终报告。

- 实验结果：


| 数据集 | B@1 | B@2 | B@3 | B@4 | M | R |
| --- | --- | --- | --- | --- | --- | --- |
| MIMIC-CXR | 0.411 | 0.277 | 0.204 | 0.158 | 0.176 | 0.320 |
| Two-view CXR  | 0.417 | 0.276 | 0.200 | 0.154 | 0.178 | 0.331 |


---

## KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models (MICCAI 2025)

- 动机： 
    - 尽管大型语言模型（LLMs）拥有丰富的知识，但在应用于如放射学报告生成（R2Gen）这类专业任务时，一个核心挑战是如何有效地激活（trigger）模型内部与特定任务相关的医学知识。
    - 仅仅依赖从图像中提取的视觉特征作为提示，可能难以捕捉到细致的、与疾病相关的信息，从而无法充分引导LLM。
    - 因此，研究的动机在于探索如何利用外部知识源来“解锁”LLM内部的潜能，以提升生成报告的临床实用性。

- 创新点：
    - 首次结合知识图谱与LLM进行知识激活： KARGEN是首个探索将一个特定于疾病的医学知识图谱与LLM相结合，用于激活和解锁LLM内部相关医学知识的框架。 
    - 新颖的特征提取与融合机制： 提出了一种新颖的知识图谱，用于提取疾病相关特征 。同时，设计了两种特征融合策略（元素级融合和模态级融合），以智能地整合“知识增强的疾病特征”和“区域图像特征”，从而平衡报告中对正常和异常内容的描述。

- 核心方法：该框架主要由四个模块构成
    1. 视觉编码器：使用Swin Transformer从输入的X光片中提取区域图像特征
    2. 知识增强编码器： 这是该框架的核心。它首先利用疾病实体名称（如“心脏扩大”）的文本嵌入作为查询，通过多头注意力机制在图像特征中找到对应的视觉证据，生成初始疾病特征 N 随后，将这些特征输入到一个由医学知识图谱（包含14个胸部疾病术语及其关联）构建的图卷积网络（GCN）中，通过信息传播和更新，提炼出最终的知识增强疾病特征
    3. 融合模块： 将代表普遍视觉内容的区域图像特征 $Z_v$ 与聚焦于病变的知识增强疾病特征 $Z_g$ 进行融合。其中，“模态级融合”策略受混合专家模型（Mixture of Experts）启发，表现更优
    4. 报告生成器： 将融合后的特征作为视觉提示，输入给一个冻结的LLAMA模型来生成最终的放射学报告。

---

## RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection (ACL 2025)

- 动机： 
    - 以往的知识增强方法常常忽略了LLM本身已经掌握的知识，导致在进行外部知识检索时引入了大量重复和冗余的信息，效率低下 
    - 同时，LLM内部学到的知识并非总是可靠，模型幻觉时有发生，这会影响报告的临床准确性。
    - 因此，研究的动机在于设计一个能够智能地区分并平衡LLM内部可靠知识与外部补充知识的框架，实现“按需补充”，而非“盲目灌输”。

- 创新点：
    - 提出“补充性知识注入”新理念： RADAR的核心创新在于其“补充性”（supplementary）知识注入策略。它不是简单地增强，而是先通过交叉验证识别出LLM已正确掌握的“高置信度内部知识”，然后仅针对知识缺口部分（即LLM遗漏或产生幻觉的部分）进行外部知识检索与注入。
    - 两阶段框架设计： 设计了一个清晰的两阶段框架，将“内部知识的识别与过滤”和“外部知识的补充与增强”分离，使得整个流程更具逻辑性和鲁棒性。
    - 引入专家模型作为“事实核查员”： 巧妙地使用一个独立训练的“专家模型”（分类器）作为参照标准，来验证LLM初步生成内容的准确性，这是过滤幻觉、识别可信知识的关键机制。

- 核心方法：该框架主要分为两个阶段，

    **第一阶段**：初步发现生成（识别内部知识）： LLM首先生成一份初步报告，并从中提取出一组观察结果 $O_R$。同时，一个独立的专家模型也对图像进行分析，得出一组观察结果 $O_I$。通过取二者的交集$O_V=O_I∩O_R$，得到高置信度的内部知识 。随后，仅保留初步报告中与$O_V$相关的句子，形成“初步发现”（PF）

    **第二阶段**：补充发现增强（注入外部知识）： 针对知识缺口（即所有可能的观察结果减去已确认的 $O_V$），系统从一个大型知识库中检索相似病例的报告。然后，仅从这些报告中提取能“补充”知识缺口的句子，形成“补充发现”（SF） 

    **最终生成**： 将PF和SF整合到输入中，形成增强的上下文，最后再由LLM生成一份完整、准确的最终报告。


## LLM-RG4: Flexible and Factual Radiology Report Generation across Diverse Input Contexts (AAAI 2025)

- 动机：
    - 现有RRG模型范式存在根本性的**“输入-输出不匹配”**问题。模型常被训练用有限的输入（如单张图像）去生成包含无法推断信息（如与历史病历的比较）的报告
    - 这种不匹配的范式是导致模型产生**“输入无关幻觉”的根源，同时也使模型缺乏灵活性**，无法适应临床实践中多变的输入场景（如是否有历史报告、是否有侧位片等）
    - 研究动机在于从根本上重塑RRG的任务范式，使其更贴近临床实践，要求模型既要灵活适应不同输入，又要保证报告内容严格基于输入，即“灵活且真实”。

- 创新点：
    - 提出新范式并构建新数据集（MIMIC-RG4）： 本研究最大的创新在于从数据和任务定义层面解决了问题。通过一个精巧的自动化流程，构建了MIMIC-RG4数据集，其中包含四种常见的临床场景，且每个场景的输入和输出都严格对应。其副产品DiscBERT模型，还开创性地提供了一种定量评估输入无关幻觉的方法 。
    - 自适应令牌融合模块（ATF）： 针对多模态输入带来的计算量剧增问题，设计了ATF模块。它通过在特征维度而非令牌维度上融合信息，使得输入给LLM的令牌数量保持恒定，极大地提升了模型的处理效率 
    - 令牌级损失加权策略（TLW）： 提出了一种直接在损失函数层面提升临床准确性的策略。它能自动识别报告中的关键诊断描述，并在训练时给予更高的损失权重，从而引导模型重点学习这些临床核心内容

- 核心方法：本研究的核心方法分为数据集构建和模型架构设计两部分

    **1. 数据集构建**： 采用“生成器-判别器”的循环流程。使用强大的Llama3-70B作为生成器，根据规则重写原始报告；同时训练一个轻量的DiscBERT作为判别器，快速判断重写是否合格。此流程反复迭代，直至报告完全符合预设场景的要求 。

    **2. 模型架构设计**：

    **ATF模块**： 将不同模态（如正面图像、侧面图像、历史报告）的特征压缩后，沿着特征维度进行拼接，再通过线性层投影回LLM所需维度。整个过程保持了令牌序列长度不变。
    
    **TLW策略**： 分两步走。首先，用CheXbert识别报告中的“阳性”或“不确定”诊断。然后，针对这些诊断，用积分梯度（IG）算法计算报告中每个词元的贡献度。最后，对贡献度高的词元所在的整个句子，在计算损失时乘以一个大于1的权重 λ 。
